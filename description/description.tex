% IEEE standard conference template; to be used with:
%   spconf.sty  - LaTeX style file, and
%   IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm]{geometry}
\usepackage[dvipsnames]{xcolor}

\input{macros}

% Bold paragraph titles.
\newcommand{\mypar}[1]{{\bf #1.}}

% To do.
\newcommand{\TODO}[1]{\textcolor{RedViolet}{\textbf{TODO:} #1}}

% Title.
\title{Secure Deletion of Sensitive Data in Protocol Implementations\\
{\large Master's Thesis Project Description}}

\author{Hugo Queinnec \\ \\ Supervisors: Linard Arquint, Prof. Dr. Peter Müller \\
Department of Computer Science, ETH Zurich}
\date{Start: 6th March 2023 \\
      End: 6th September 2023 \\
}

\begin{document}

\maketitle

% Enable page numbers.
\thispagestyle{plain}
\pagestyle{plain}


\section{Introduction}
% Better introduce (follow points 1 to 4 from comments) + introduce the thesis goal (Motivation 3.1).
% 1. Security protocols are ubiquitous (everywhere)
% 2. Protocols and their implementation should be correct because high stakes are at risk (banking)
% 3. We need to guarantee security properties: it is not easy (worst case, infinity of executions)
% 4. Lots of research on protocol verification, but we also need guarantees for implementations
% 5. While [authors + citation] propose a promising methodology for verifying security properties for protocol implementations, they cannot reason about sensitive data that must be deleted in a timely manner. This is crucial for proving strong security properties such as post-compromise security.

Security protocols are omnipresent in our daily lives, they are the foundation for many applications ranging from online banking to text messaging. These protocols employ cryptography to achieve fundamental security properties such as authentication and confidentiality.
Online banking operations serve as a prime example of how heavily we rely on security protocols. A breach in the security of these protocols could lead to substantial financial losses, which is why it is essential that these protocols and their implementations are both correct and secure.
% For example, proving a property such as \emph{injective agreement} protects against replay attacks and prevents a transaction to be repeated multiple times.
For example, proving a property such as \emph{injective agreement} protects against replay attacks, meaning that the protocol participants reject messages that an attacker might have obtained in the past and tries to send them again. In our online banking example, such a message could contain the request to perform a certain transaction, and it is thus crucial that this request cannot be replayed by an attacker.

Guaranteeing security properties of protocols is a challenging task, especially in the presence of a strong attacker (developed in section \ref*{sec:symbolic-analysis}). In order to ensure these properties for all possible protocol executions, verification must consider an arbitrary number of participants and protocol sessions, as well as any possible ordering of protocol steps. Furthermore, protocol security properties are generally not local to a particular participant but global, such as mutual authentication between two parties. This presents an additional challenge for verification as it requires a global view of the protocol execution.

When reasoning about correctness, two aspects of the protocol must be considered: the high-level protocol itself (that we will call \emph{model}), and its implementation. Proving security properties for a protocol model is an active field of research and several promising automatic verifiers have been proposed (like Tamarin \cite{meier2013tamarin} and ProVerif \cite{blanchet2016modeling}). However, a verified protocol model does not imply that an implementation is free of security vulnerabilities and achieves the same security properties as its model. This is why we focus on verifying security properties for protocol implementations.

While Arquint and al.\cite{arquint2022generic} propose a promising methodology for verifying security properties for protocol implementations, they cannot reason about sensitive data that must be deleted in a timely manner.
This is a limitation for proving advanced security properties, such as forward secrecy and post-compromise security, for protocols that periodically renew keys, like Signal \cite{marlinspike2016x3dh}.
% Forward secrecy guarantees that an attacker cannot compute the session keys of an already established session after learning the long-term secret keys.
Forward secrecy informally guarantees that past keys remain secret even when newer keys or long-term keys become known to the attacker.
It is crucial for secure communication, as it ensures that an attacker cannot decrypt past messages even if they manage to compromise a participant later on.
Post-compromise security informally means that a participant can communicate securely with a peer, even when certain secrets leaked \emph{in the past}.
%even if the peer’s secrets have already been (partly) compromised \cite{7536374}.
This is sometimes referred to as \emph{healing}, which allows a communication to resume securely at some point after a compromise.

Protocols like Signal achieve both of these properties by using a key rotation scheme within a session, where a communication key is used to generate its successor and is then deleted. The goal of this thesis is to extend the methodology by Arquint et al. to prove that time-sensitive data, such as this communication key in the case of Signal, has been securely deleted. This allows us to prove forward secrecy and post-compromise security properties for protocol implementations that employ a key rotation scheme.

\section{Background}

\subsection{Symbolic Protocol Analysis}
\label{sec:symbolic-analysis}

This research work is a continuation of the study of symbolic methods for protocol analysis.
% In this model, we are abstracting concrete bit-strings to algebraic \emph{terms}.
% , which can be used to express properties written as logical expressions.
We use the symbolic model of cryptography, where we assume that the cryptographic primitives are secure, i.e. the plaintext can only be obtained from a ciphertext if decryption is performed with the correct decryption key.
% We also assume that all operations are performed on symbolic terms rather than at the byte level.
We assume that all operations are performed on symbolic \emph{terms} instead of bytes, which is why we abstract concrete bit-strings to terms.

Furthermore, we consider a Dolev-Yao\cite{dolev1983security} attacker present in the network. This attacker can perform arbitrary operations on this term level, has full control over the network (including reading and sending any message), and can corrupt any participant (which means that the attacker learns all the terms contained in the participant's state).

A common procedure for modeling protocols in this setting is to consider a trace. This trace records the sequence of protocol events in a particular run of the protocol.
Security properties can be expressed as a logical expression about a trace, and then verified by checking whether it holds for all possible traces of the protocol.
Automated provers like Tamarin and ProVerif can verify certain security properties for a protocol \emph{model} by analyzing all its possible traces.

When considering the verification of protocol \emph{implementations}, traces can also be used. The overall idea is to extend the implementation with a trace data structure that is used to record protocol operations. In order to reason about the whole protocol (and not a single execution), we define a \emph{trace invariant}. It is a property that every prefix of any trace of the protocol must satisfy.
Verifying the protocol implementation ultimately consists in proving that each action of a participant or the attacker maintains the trace invariant, and then proving that the invariant implies the intended security properties.

In the following, we will introduce two existing approaches in this verification setting  aiming at verifying high-level security properties for protocol \emph{implementations}. These approaches are the main basis for our work.

\subsection{DY*}

DY*\cite{bhargavan2021text} is a framework for proving security properties about protocol implementations written in the F* programming language.
Using a particular code structure and a particular way of storing program state, DY* is able to account for some implementation-level specificities.

DY* uses a \emph{global trace} to model the global execution state of the protocol.
When a protocol participant is taking a protocol step, it first reads its serialized state from the trace, deserializes it, performs the step, and then saves its new serialized state to the trace. This trace is append-only and existing entries cannot be modified or deleted. In addition to state changes, the trace records all operations that are important for proving security properties (nonce generation, sent messages, and corruption).
% The attacker can perform these operations at any time as well.
Ultimately, this global trace contains each participant's current and all past states, and provides a global view over the entire distributed system. % such that global properties can be expressed and proven.
DY* achieves modular reasoning by specifying a trace invariant and verifying that each function modifies the global trace only in ways that maintain the trace invariant. Global security properties can then be proved from this trace invariant.

On the global trace, each state is annotated with a \emph{session state identifier} to indicate to which participant and protocol session it belongs. This models the fact that a participant may be involved in multiple independent protocol sessions simultaneously. The session state identifier includes a \emph{version} that distinguishes between different phases within a protocol session, as explained in detail in section \ref*{sec:existing-approach-dy}.

Each participant's state comprises several values that together constitute the program state of the participant at that point in time. Each of these values is assigned a secrecy label, indicating which participants are allowed to read the value.
% In DY*, if an attacker corrupts a participant or one of its sessions (possibly with a specific version), they will obtain all values having the corrupted session state identifier as a secrecy label.

Protocol implementations written in F* and verified with DY* are executable, but require a special runtime environment that provides access to the trace. Additionally, the DY* framework is composed of a library, containing protocol-independent parts that only need to be verified once, and can then be reused across different protocols. This significantly reduces the overall verification time.

\subsection{Modular verification of existing implementations}

% The DY* framework is limited to verifying protocol implementations written in the functional F* language and makes several assumptions on how implementations are structured and how program state is stored.
The DY* framework can only verify protocol implementations written in the functional F* language that adhere to certain assumptions about their structure and program state storage.
% However, there are many existing protocol implementations written in various languages that cannot be verified with this approach.
However, these assumptions do not hold in general for existing implementations.
Arquint et al.\cite{arquint2022generic} present a methodology for verifying existing heap-manipulating protocol implementations. This methodology is agnostic to the programming language and relies only on standard features present in most separation logic-based verifiers. In the following, we will focus on Go implementations and the Gobra\cite{wolf2021gobra} verifier.

This methodology is inspired by DY* and also uses a global trace to provide a global view over the entire system.
% Arbitrary code structure
To address the issue of arbitrary code structure in existing implementations, the trace is treated as a concurrent data structure. It allows arbitrary interleavings of operations, in a more fine-grained manner than arbitrary interleavings of protocol steps in DY*, which is crucial for soundness in this setting.
% Program state management
As existing implementations manage program state in their unique ways, we cannot assume that they store the state on the trace or rewrite implementations to do so. Instead, \emph{local invariants} are used to relate program state stored at the local participant-level with the global trace invariant.
The global trace only records a sequence of events corresponding to high-level operations (similar to DY*, except for the state storage entry) that must maintain a trace invariant, which is used to prove global security properties.
% Ghost
Unlike DY*, the global trace is a \emph{ghost} data structure for verification-only purposes, which will be erased before compilation. As such, the global trace has no impact on the runtime behavior or performance.

Verification is based on separation-logic, which allows us to reason about heap manipulations. Furthermore, separation-logic's resources are used to prove injective agreement, which is to the best of our knowledge not possible with DY*.
% Building on this, strong security properties can be expressed and proved such as injective agreement, which excludes replay attacks. This was not possible with DY*.

Similarly to DY*, this methodology comes with a library that allows to reuse protocol-independent parts (verified only once) across different protocol implementations.

\section{Secure deletion of data}
% General idea - Existing approaches - Challenges of a new approach

\subsection{Security properties}

As mentioned, some protocols achieve strong security properties by frequently renewing their keys within the same protocol session. This is notably the case in the Double-Ratchet Protocol \cite{perrin2016double}, which is a major component of the Signal protocol.

A session of the Double-Ratchet protocol requires frequent renewal of a shared secret between two participants using the Diffie-Hellman ratchet.
Then for every message, a \emph{communication key} is derived (from the current shared secret, using a key derivation function) and used to encrypt the message.
% By executing the same computation steps, the participants can derive the same communication keys and decrypt received messages.
The Double-Ratchet protocol is designed to be secure against an attacker recording all previous encrypted messages and obtaining a shared secret or a communication key at some point.
If the attacker compromises a participant, for example Alice, he may be able to decrypt some messages using the keys and secrets stored in Alice's memory. If Alice keeps storing all previous secrets and session keys, then the attacker would be able to decrypt all previous messages that he previously observed on the network. This is why it is crucial for Alice to delete previous secrets and communication keys as soon as she has derived the new ones.
Indeed, if previous keys are correctly deleted from Alice's memory, then the attacker may only be able to decrypt the last message(s), and not all previous ones.

Therefore, the Double-Ratchet protocol satisfies forward secrecy. This property is enabled by two main factors: cryptographically preventing past communication keys from being derived only from the long-term secret and current communication keys, and securely deleting previous keys.

Post-compromise security, as briefly introduced earlier, is not achievable after the \emph{unrestricted} compromise of a participant: the initiator would have no guarantee to be in communication with the intended peer because the attacker could act exactly like the peer.
We instead consider the formalized notion of post-compromise \emph{via state} \cite{7536374}:
a participant can communicate securely with a peer during a session even when long-term keys have been leaked as long as there is some secret data available exclusively to the participants.
%a participant can communicate securely with a peer during a session, even if the adversary compromises all but one exchange of messages before this session.
To be able to prove this property, we must be able to prove that a certain state in the past, to which an attacker has gained access, does not contain the secret data on which the future communication depends. %we must ensure that for example, a single old state does not contain some future session keys.
% Otherwise, corrupting this single state would allow the attacker to decrypt all future messages encrypted with those keys (violating post-compromise via state).
% Though this is not directly related to memory deletion, it shows why it is crucial to have session keys existing only during some lapse of time.
Although post-compromise security is not directly related to secure deletion, it requires a fine-grained reasoning about the data occurring in a participant's state at a particular point in time. As we will see in section \ref*{sec:our-approach}, the same mechanism as for forward secrecy can be applied.

% Enabling our verification methodology to proves these two strong security properties will therefore require to introduce a notion of temporality, to specify the lapses of time during which keys are available. Outside these lapses, keys should not be present in memory, but either not-yet-generated or deleted.
Our methodology to prove these two strong security properties requires a notion of temporality because we have to specify the lapses of time during which certain keys are available. Outside these lapses, keys must not be present in memory because they have either not been generated yet or have already been securely deleted.


\subsection{Existing approach and its shortcomings}
\label{sec:existing-approach-dy}
% Introduce versions, then discuss the solution

% The DY* framework supports proving forward secrecy and post-compromise security.
% Indeed, it supports the deletion of old data and has a sense of temporality.

DY* uses a \emph{version} label for each session, in order to indicate temporality. Initially, all versions are 0 and are incremented at some times to represent new protocol phases. Values with version \textit{x} can only occur in states within phase \textit{x} of the protocol. DY* enforces this restriction with a suitable invariant over states. Thus, only data of the current version can be stored, ensuring that neither outdated keys nor future keys are present in memory. Building on this, they are able to prove forward secrecy and post-compromise security for protocols like Signal.

However, DY* does not enforce that outdated keys are securely deleted from memory. They only show that they are not present in the current scope, but outdated keys are not explicitly zeroed out from memory.
%  and may still be physically present.
Moreover, this solution is not applicable to existing implementations because their state is not stored on a trace, making it impossible to express such an invariant.
% without making significant modifications to the implementations.
Furthermore, DY* enforces the invariant over state only at certain time points, namely when the state is stored on the trace, without taking into account the state in-between.
% However, some existing implementations may necessitate a more precise granularity to analyze the state. For instance, there may be a brief moment during which both the old and new keys are in use and present in the memory.

% This and the next sentence are not fully clear. I'd argue as follows:
% - methods in existing implementations might be long running (or even non-terminating)
% - enforcing the invariant at the beginning and end is thus not sufficient or would otherwise result in a weird attacker model (i.e. we would implicitly assume that the attacker cannot access the program state most of the time (when the program is stuck in e.g. the infinite loop))
% - we thus want an invariant that *always* holds over the local state instead of only at certain time points
% - thus, we also must account for the case during generating the next key that *for a short period* we must allow keys of the current and next version / phase simultaneously be present in the state

However, some existing implementations may contain long-running or non-terminating methods. It would not be sufficient to enforce the invariant only at the beginning and at the end of these methods, as this would result in an unrealistic attacker model where the attacker is assumed to not have access to the program state most of the time. Therefore, we want to have an invariant that always holds over the local state instead of only at certain times. 
% Thus, we also must account for the case during generating the next key that for a \emph{short period} we must allow keys of the current and next version to simultaneously be present in the state.
This invariant must be designed to account for the situation during key generation where keys of both current and next versions may coexist in the state for a \emph{short period}.

% While the approach of Arquint et al. does not have such a versioning mechanism to indicate temporality, it is a better basis for our approach as we target existing implementations.
% Since participant states are not serialized and stored on the global trace, it is not possible to use the same approach as for DY* and memory deletion must be handled explicitly.


\subsection{Our approach}
\label{sec:our-approach}

This thesis extends the methodology of Arquint et al. by introducing a notion of temporality and by enforcing secure deletion of sensitive data.
We aim for a language-agnostic solution that can be applied to existing implementations performing key rotations, such as implementations of Signal and the Double-Ratchet Protocol. This extension will allow us to prove forward secrecy and post-compromise security for these protocol implementations.

Our approach will use a mechanism similar to that of DY* \emph{versions} to indicate the lapses of time during which sensitive data can be present in memory.
% This mechanism will ensure that outdated sensitive data is safely deleted.
However, we have to develop a modular verification technique to ensure that sensitive data is guaranteed to be absent in all other lapses of time.

Currently, any creation of an array of bytes (i.e. creation of nonce, keys, etc.) is controlled by a memory predicate \texttt{Mem}.
The \texttt{Mem} predicate is used to abstract over the memory of a byte array and thus specifies permissions to every byte in the array.
The predicate body is shown in figure~\ref{lst:mem} only for illustration purposes, because the predicate is in fact abstract, meaning that clients of the reusable verification library cannot get direct access to the individual bytes of the array and instead have to perform all operations via corresponding library calls.
% This predicate is meant to verify that the participant gets the permission to each byte of the array and then returns it. This simple memory predicate looks like figure \ref{lst:mem}.

\begin{figure}[h]
  \begin{gobra}
      pred Mem(s []byte) {
            forall i int :: 0 <= i && i < len(s) ==> acc(&s[i])
      }
  \end{gobra}
  \caption{Illustrative body of the current memory predicate in the Go reusable verification library.}
  \label{lst:mem}
\end{figure}

For this thesis, we add a notion of temporality via a separate memory predicate.
Thinking about how to design such a predicate will be a first challenge of this thesis.
One possible approach is a new memory predicate that marks byte arrays that require secure deletion at the end of their lifetime and has an additional parameter specifying the byte array's \emph{version} (i.e. lifetime).
% Thinking about how to design such a predicate will be a first challenge of this thesis, but one could imagine using a \emph{version} parameter for the new \texttt{Mem} predicate to represent temporality.

However, we have to ensure that variables are actually deleted from memory as specified by the memory predicate. If we use \emph{version}, it would mean to ensure that variables with a version \texttt{v} are deleted from memory before the protocol transitions to version \texttt{v+1}.

We can treat this new memory predicate not only as a predicate abstracting over memory but also as an obligation to securely delete the associated value from memory. %to delete it securely.
To do this, we can enforce, when the protocol version changes, that all instances of this new memory predicate have an appropriate version number.
Additionally, \emph{leak checks} can be implemented
%for functions that require a permission to this new predicate to ensure that the permission is returned after the function call.
to ensure that all predicate instances are returned after function calls.
This enforces that byte arrays with a version have to be deleted with a dedicated secure deletion function before the protocol version is incremented. This delete function would be the only way to discharge obligations resulting from the new memory predicate.

Gobra does not support leak checks yet but Viper~\cite{muller2016viper}, on which Gobra builds, offers \texttt{forperm} expressions that allow us to encode them.
In order to achieve our final goal of supporting properties like forward secrecy in the reusable verification library, we will have to extend the library with this new memory predicate, a library method that we assume securely deletes memory, and leak checks. For the latter, we have to extend Gobra to support obligations, building on Viper's \texttt{forperm} expressions.

% A way to proceed could be to implement an obligation mechanism in Gobra, encoded on top of Viper's \texttt{forperm} quantifier. The goal would be to obtain a delete function, that would be the only way to discharge obligations coming from the new memory predicate. By doing so, we could have an invariant checking that all sensible values have the same version number as a global version variable representing the protocol phase. Therefore, we could only move on to the next phase and increment the global version variable if all sensitive variables had been removed (which means that their obligations should have been discharged with the delete function).

\section{Core Goals}

\begin{itemize}
      \item \textbf{Methodology.} Present a methodology that extends Arquint's and al. work on protocol implementation verification, and that would allow to verify the deletion of old data in a protocol implementation. This methodology would ultimately allow the verification of high-level security properties relying on data deletion, such as forward secrecy.
      \item \textbf{Extension of Gobra.} Extend the Gobra verifier to provide an obligation mechanism on top of Viper's primitives.
      % Extend the Gobra verifier to support the deletion of old data, based on existing Viper's primitives.
      % Support will be limited to particular functions that will be useful for implementing the verification library extension in the next step.
      % This may come down to implementing an obligation discharge mechanism, that would then be used to discharge obligations coming from the new memory predicates.
      \item \textbf{Extension of the Go Reusable Verification Library.} Extend the reusable verification library to support the deletion of old data, based on the new functionalities added to the Gobra verifier at the previous step. The library will then provide higher-level APIs to handle the deletion mechanism, that will be useful for verifying protocol implementations.
      \item \textbf{Implementation of an example protocol.} Using the previously extended verification library, implement and verify a small protocol relying on frequent deletion of sensitive data. Verifying a high-level property such as forward secrecy will showcase the potential of the methodology.
      \item \textbf{Evaluation.} Evaluate the newly developed methodology and its application to the example protocol, both qualitatively and quantitatively, by evaluating the performance of the new Gobra functionality for checking obligations. Discuss its potential and its limitations, and see how it compares to existing approaches, such
      as DY*.

\end{itemize}

\section{Extension Goals}

\begin{itemize}
      \item \textbf{Case study of a solution based on linear types.} The Gobra verifier may benefit from a linear type system in the future. Byte-arrays with the new memory predicate act like linear resources that are created by a particular library call and have to be deleted by another one. Investigate what a solution to our initial problem might look like if we take advantage of the possibilities offered by a linear type system.
      \item \textbf{Verification of an existing protocol.} Find an existing protocol that uses memory deletion in order to obtain security properties such as forward secrecy and post-compromise security. Find an implementation of this protocol in Go, if possible an official implementation, and verify it using the developed methodology and extended verification library.
      % \item \textbf{Case study on the use of our Gobra extensions.} Look if the extensions added to the Gobra verifier could have a use outside our specific use for protocol implementation verification. If so, it may be interesting to further develop Gobra extensions to provide better support to these newly found use cases.
\end{itemize}



% This place holder texts just shows how you can use the Gobra and Viper listings.
% For example, Listing~\ref{lst:echoServer}
% shows a Python class while Listing~\ref{lst:silver_fields} shows a
% method in the Viper~\cite{viper} language. For smaller code fragments,
% use this \gl+f(a,b)+. 

% \begin{figure}
%   \begin{gobra}
%     class Server(Thread):
%       def run():
%         server_socket = create_server_socket()
%         while True:
%           client_socket = server_socket.accept()
%           data = client_socket.read_all(timeout=1)
%           if data:
%             print(client_socket.address)
%             client_socket.send(data)
%           client_socket.close()
%   \end{gobra}
%   \caption{Echo server.}
%   \label{lst:echoServer}
% \end{figure}

% \begin{figure}
%     \begin{myViper}
%       field f: Int
%       field g: Int
%       method get_f(arg: Ref) returns (res1: Int,
%                                       res2: Int)
%         requires acc(arg.f)
%         ensures acc(arg.f) && res1 == arg.f
%       {
%         res1 := arg.f
%       //res2 := arg.g   // Verification error: might
%                         // not have permission to
%                         // access arg.g.
%       }
%     \end{myViper}
%     \caption{A simple getter method. The assignment to the result
%         variable \vl+res2+ fails to verify because the method does
%         not have a permission to access field \vl+arg.g+.}
%     \label{lst:silver_fields}
% \end{figure}

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: bibl_conf). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEtran}
\bibliography{refs}
\end{document}
